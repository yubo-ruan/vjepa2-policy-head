# V-JEPA 2 Policy Configuration

# V-JEPA 2 Encoder
vjepa2:
  # Path to local checkpoint (preferred)
  model_path: "/workspace/models/vjepa2-ac-vitg.pt"
  # Model variant
  model_name: "vjepa2_vitg"
  # Freeze encoder weights
  freeze: true
  # Number of input frames
  num_frames: 16
  # Image size (256 for ViT-G)
  image_size: 256
  # Use AttentivePooler for aggregation
  use_attentive_pool: true

# Proprioception Encoder
proprio:
  # Input dimension: ee_pos(3) + ee_ori(3) + gripper(2) + joint_pos(7) = 15
  dim: 15
  # Number of history frames
  history_len: 5
  # Output embedding dimension
  output_dim: 256

# Policy Head
policy:
  # Transformer hidden dimension
  hidden_dim: 512
  # Number of attention heads
  n_heads: 8
  # Number of transformer layers
  n_layers: 4
  # Number of context tokens per modality
  n_context_tokens: 4
  # Action dimension (7 for LIBERO: 3 pos + 3 rot + 1 gripper)
  action_dim: 7
  # Action chunk size
  chunk_size: 50
  # Dropout rate
  dropout: 0.1

# Training
training:
  batch_size: 32
  learning_rate: 0.0001
  weight_decay: 0.00001
  epochs: 100
  warmup_epochs: 5
  grad_clip: 1.0
  # Seed for reproducibility
  seed: 42

# Evaluation
evaluation:
  # Execute this many actions before replanning
  execute_steps: 10
  # Maximum episode length
  max_episode_steps: 300
  # Episodes per task for evaluation
  n_episodes_per_task: 20
  # Suites to evaluate (valid: libero_object, libero_spatial, libero_goal, libero_90, libero_10)
  suites:
    - "libero_object"
    - "libero_spatial"
    - "libero_goal"

# Data
data:
  # Path to LIBERO demonstrations
  libero_path: "/workspace/data/libero"
  # Default suite
  suite: "libero_object"
  # Train/val split ratio
  train_ratio: 0.9
  # Sample stride (reduce overlap between samples)
  sample_stride: 5

# Logging
logging:
  # Weights & Biases project name
  wandb_project: "vjepa2-policy"
  # Log every N steps
  log_every: 10
  # Save checkpoint every N steps
  save_every: 1000
  # Checkpoint directory
  checkpoint_dir: "/workspace/checkpoints"
